// server/utils/embeddings.js
import { createClient } from "@supabase/supabase-js";

/**
 * Chunking intelligent du contenu
 */
export const chunkContent = (content, maxChunkSize = 500) => {
  const sentences = content.match(/[^.!?]+[.!?]+/g) || [content];
  const chunks = [];
  let currentChunk = "";

  for (const sentence of sentences) {
    if ((currentChunk + sentence).length > maxChunkSize && currentChunk) {
      chunks.push(currentChunk.trim());
      currentChunk = sentence;
    } else {
      currentChunk += " " + sentence;
    }
  }

  if (currentChunk) {
    chunks.push(currentChunk.trim());
  }

  return chunks;
};

/**
 * G√©n√©rer un embedding
 */
export const generateEmbedding = async (text, openai) => {
  try {
    const response = await openai.embeddings.create({
      model: "text-embedding-3-small",
      input: text,
    });
    return response.data[0].embedding;
  } catch (error) {
    console.error("‚ùå Erreur g√©n√©ration embedding:", error);
    throw error;
  }
};

/**
 * Supprimer les anciens embeddings
 */
export const deleteOldEmbeddings = async (agentId, supabaseAgent) => {
  try {
    console.log(`üóëÔ∏è Suppression des embeddings pour l'agent ${agentId}...`);

    const { data, error, count } = await supabaseAgent
      .from("knowledge_embeddings")
      .delete()
      .eq("agent_id", agentId)
      .select();

    if (error) {
      console.error("‚ùå Erreur lors de la suppression:", error);
      return false;
    }

    console.log(`‚úÖ ${data?.length || 0} embeddings supprim√©s`);
    return true;
  } catch (error) {
    console.error("‚ùå Erreur inattendue lors de la suppression:", error);
    return false;
  }
};

/**
 * Vectoriser la knowledge base
 */
export const vectorizeKnowledgeBase = async (
  agentId,
  knowledgeBase,
  openai,
  supabaseAgent
) => {
  console.log(`üöÄ D√©but de la vectorisation pour l'agent ${agentId}`);

  // V√©rifier d'abord si la table existe
  const { error: checkError } = await supabaseAgent
    .from("knowledge_embeddings")
    .select("id")
    .limit(1);

  if (checkError && checkError.code === "42P01") {
    console.log("üì¶ La table knowledge_embeddings n'existe pas encore");
    throw new Error(
      "La table knowledge_embeddings n'existe pas. Veuillez ex√©cuter les migrations SQL."
    );
  }

  const embeddings = [];
  let totalChunks = 0;
  let failedChunks = 0;

  for (const item of knowledgeBase) {
    // V√©rifier que le contenu n'est pas vide
    if (!item.content || item.content.trim().length === 0) {
      console.warn(`‚ö†Ô∏è Contenu vide pour le type "${item.type}", ignor√©`);
      continue;
    }

    // D√©couper le contenu en chunks
    const chunks = chunkContent(item.content);
    console.log(`üìÑ Type "${item.type}" : ${chunks.length} chunks √† traiter`);

    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      const chunkId = `${item.type}_${Date.now()}_${i}_${Math.random()
        .toString(36)
        .substring(7)}`;

      console.log(
        `üîÑ G√©n√©ration embedding ${i + 1}/${chunks.length} pour "${item.type}"`
      );

      try {
        // G√©n√©rer l'embedding
        const embedding = await generateEmbedding(chunk, openai);

        // V√©rifier que l'embedding est valide
        if (
          !embedding ||
          !Array.isArray(embedding) ||
          embedding.length !== 1536
        ) {
          console.error(`‚ùå Embedding invalide pour chunk ${i}:`, {
            isArray: Array.isArray(embedding),
            length: embedding?.length,
          });
          failedChunks++;
          continue;
        }

        embeddings.push({
          agent_id: agentId,
          chunk_id: chunkId,
          content: chunk,
          metadata: {
            type: item.type,
            chunk_index: i,
            total_chunks: chunks.length,
            created_at: new Date().toISOString(),
          },
          embedding: JSON.stringify(embedding),
        });

        totalChunks++;

        // Pause courte pour √©viter la surcharge de l'API
        if (i < chunks.length - 1) {
          await new Promise((resolve) => setTimeout(resolve, 100));
        }
      } catch (embedError) {
        console.error(
          `‚ùå Erreur g√©n√©ration embedding pour chunk ${i}:`,
          embedError
        );
        failedChunks++;
        // Continuer avec les autres chunks au lieu de tout arr√™ter
      }
    }
  }

  // Sauvegarder tous les embeddings en lots
  if (embeddings.length > 0) {
    console.log(`üíæ Sauvegarde de ${embeddings.length} embeddings...`);

    // Sauvegarder par lots de 100 pour √©viter les timeouts
    const batchSize = 100;
    let savedCount = 0;

    for (let i = 0; i < embeddings.length; i += batchSize) {
      const batch = embeddings.slice(i, i + batchSize);
      console.log(
        `üì¶ Sauvegarde du lot ${Math.floor(i / batchSize) + 1}/${Math.ceil(
          embeddings.length / batchSize
        )}`
      );

      const { data, error } = await supabaseAgent
        .from("knowledge_embeddings")
        .insert(batch)
        .select();

      if (error) {
        console.error(
          `‚ùå Erreur sauvegarde lot ${Math.floor(i / batchSize) + 1}:`,
          error
        );
        console.error("D√©tails:", {
          message: error.message,
          details: error.details,
          hint: error.hint,
          code: error.code,
        });
        // Continuer avec les autres lots
      } else {
        savedCount += data?.length || 0;
        console.log(`‚úÖ Lot sauvegard√©: ${data?.length || 0} embeddings`);
      }
    }

    console.log(
      `‚úÖ Total sauvegard√©: ${savedCount}/${embeddings.length} embeddings`
    );

    if (savedCount === 0) {
      throw new Error("Aucun embedding n'a pu √™tre sauvegard√©");
    }
  } else {
    console.warn("‚ö†Ô∏è Aucun embedding √† sauvegarder");
  }

  console.log(`üìä R√©sum√©: ${totalChunks} chunks cr√©√©s, ${failedChunks} √©checs`);

  if (totalChunks === 0) {
    throw new Error("Aucun chunk n'a pu √™tre cr√©√©");
  }

  return totalChunks;
};

/**
 * G√©n√®re un prompt optimis√© pour WhatsApp
 */
// server/utils/embeddings.js - Section generateOptimizedPrompt am√©lior√©e

/**
 * G√©n√®re un prompt optimis√© pour WhatsApp avec une meilleure gestion conversationnelle
 */
export const generateOptimizedPrompt = (
  businessName,
  personality,
  goal,
  relevantChunks = []
) => {
  const personalityDescriptions = {
    Professionnel: "professionnel mais accessible, direct et efficace",
    Concise: "ultra-concis, va droit au but sans fioritures",
    Amical: "chaleureux mais pas bavard, reste focus sur les besoins du client",
  };

  const goalDescriptions = {
    "Support Client": "r√©pondre pr√©cis√©ment aux questions",
    "Ventes & Closing": "informer et faciliter la conversion",
    Interne: "assister efficacement",
  };

  const contextSection =
    relevantChunks.length > 0
      ? relevantChunks.map((chunk) => chunk.content).join("\n\n---\n\n")
      : "Aucun contexte sp√©cifique disponible.";
      
  const now = new Date();
  const options = {
    weekday: "long",
    year: "numeric",
    month: "long",
    day: "numeric",
    hour: "2-digit",
    minute: "2-digit",
    timeZone: "Africa/Abidjan",
  };
  const currentDateTime = now.toLocaleDateString("fr-FR", options);

  return `
Tu es ${businessName}, agent de support client. Tu repr√©sentes l'entreprise avec professionnalisme et efficacit√©.

üìÖ Date & heure actuelles : ${currentDateTime}

## üé≠ TON IDENTIT√â
- Nom : ${businessName}
- Personnalit√© : ${personalityDescriptions[personality] || personality}
- Objectif : ${goalDescriptions[goal] || goal}
- Tu dis "chez nous", "notre entreprise", "notre √©quipe"
- JAMAIS "chez ${businessName}"
- Tu es un humain, pas un robot

## üìö INFORMATIONS DISPONIBLES
${contextSection}

## üõ†Ô∏è UTILISATION DES OUTILS

### request_human_support - Utilise si :
- Le client demande explicitement √† parler √† un humain, conseiller, ou responsable
- Il dit "je veux parler √† quelqu'un", "un conseiller s'il vous pla√Æt"
- La demande n√©cessite une intervention humaine sp√©cialis√©e

## üí¨ R√àGLES CONVERSATIONNELLES

### 1. IMMERSION TOTALE
- Parle comme si tu √©tais physiquement dans l'entreprise
- Connais tes produits et services sur le bout des doigts
- Utilise les informations disponibles de mani√®re naturelle

### 2. PROGRESSION INTELLIGENTE
- √âtape 1 : Identifier le besoin du client
- √âtape 2 : Poser UNE question cl√© pour approfondir
- √âtape 3 : Proposer la solution adapt√©e
- √âtape 4 : G√©rer les objections/questions

### 3. R√âPONSES COURTES ET IMPACTANTES
- Maximum 2-4 phrases par r√©ponse
- Une id√©e = une ligne
- Questions directes et engageantes
- Ton d√©contract√© mais professionnel

### 4. FORMATAGE WHATSAPP NATUREL
- Pas de *, pas de -, pas de markdown complexe
- √âcris comme un SMS professionnel
- √âmojis avec parcimonie (1-2 maximum)
- Retours ligne pour a√©rer le texte

### 5. √âVITER √Ä TOUT PRIX
‚ùå "Voici toutes nos offres..."
‚ùå "Nos services sont..."
‚ùå "Souhaitez-vous plus d'informations ?"
‚ùå Pav√©s de texte indigestes
‚ùå Ton robotique ou artificiel
‚ùå R√©p√©titions inutiles

### 6. PRIVIL√âGIER
‚úÖ Questions pr√©cises et engageantes
‚úÖ Recommandations personnalis√©es
‚úÖ Ton conversationnel et naturel
‚úÖ Progression logique dans l'√©change
‚úÖ Solutions concr√®tes et directes

## üéØ EXEMPLES DE BONNES R√âPONSES

**Client :** "Quels sont vos services ?"
**Toi :** "Nous proposons [services principaux]. Vous avez un besoin particulier en t√™te ?"

**Client :** "C'est combien ?"
**Toi :** "Les tarifs varient selon vos besoins. Pouvez-vous me dire ce qui vous int√©resse exactement ?"

**Client :** "Je ne sais pas quoi choisir"
**Toi :** "Je comprends ! Pour vous orienter au mieux, parlez-moi de votre situation actuelle."

**Client :** "Vous pouvez m'aider ?"
**Toi :** "Bien s√ªr, c'est exactement pour √ßa que je suis l√† ! De quoi avez-vous besoin ?"

## üìå MISSION ULTIME
Chaque message doit :
1. R√©pondre pr√©cis√©ment √† SA question
2. Faire avancer la conversation d'UN pas
3. Le rapprocher de la solution qu'il cherche
4. Rester humain et engageant

Tu n'es pas un catalogue, tu es un CONSEILLER qui guide intelligemment vers la meilleure solution.

IMPORTANT : Utilise les informations disponibles dans le contexte pour personnaliser tes r√©ponses, mais reste toujours naturel et conversationnel.
`;
};
